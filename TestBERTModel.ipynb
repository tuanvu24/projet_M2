{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "492db99a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "492db99a",
        "outputId": "75365b65-e7c7-4b87-bc39-1e81c5398c76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# drive à importer : https://drive.google.com/drive/folders/1vn_RM47LA_HdpQwZqdwqNRPm7CXyeeV3?usp=sharing\n",
        "# \n",
        "#1 chargement des datas\n",
        "\n",
        "#Nous allons tester la classification binaire \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47bcf75a",
      "metadata": {
        "id": "47bcf75a"
      },
      "outputs": [],
      "source": [
        "# Définit le chemin vers le dossier contenant les différentes types de datas\n",
        "\n",
        "###WhisperX\n",
        "\n",
        "#whisperX \n",
        "folder_path_whisperX_ad = \"/content/drive/MyDrive/Alzheimer_transcripts/transcriptions/whisperX/ad\"\n",
        "folder_path_whisperX_cn = \"/content/drive/MyDrive/Alzheimer_transcripts/transcriptions/whisperX/cn\"\n",
        "\n",
        "#whisperX with segmented 30sec audios length\n",
        "folder_path_whisperX_ad_seg = \"/content/drive/MyDrive/Alzheimer_transcripts/transcriptions/whisperX_seg/ad\"\n",
        "folder_path_whisperX_cn_seg = \"/content/drive/MyDrive/Alzheimer_transcripts/transcriptions/whisperX_seg/cn\"\n",
        "\n",
        "#whisperX with segmented 30sec audios length and whistespaces representation \n",
        "folder_path_whisperX_ad_ws_seg = \"/content/drive/MyDrive/Alzheimer_transcripts/transcriptions/whisperX_seg/white_spaces_ad\"\n",
        "folder_path_whisperX_cn_ws_seg = \"/content/drive/MyDrive/Alzheimer_transcripts/transcriptions/whisperX_seg/white_spaces_cn\"\n",
        "\n",
        "\n",
        "#whisperX with whistespaces representation \n",
        "folder_path_whisperX_ad_ws = \"/content/drive/MyDrive/Alzheimer_transcripts/transcriptions/whisperX/white_spaces_ad\"\n",
        "folder_path_whisperX_cn_ws = \"/content/drive/MyDrive/Alzheimer_transcripts/transcriptions/whisperX/white_spaces_cn\"\n",
        "\n",
        "\n",
        "\n",
        "###Whisper classic\n",
        "folder_path_whisper_ad = \"/content/drive/MyDrive/Alzheimer_transcripts/transcriptions/whisper/ad\"\n",
        "folder_path_whisper_cn = \"/content/drive/MyDrive/Alzheimer_transcripts/transcriptions/whisper/cn\"\n",
        "\n",
        "###Whisper classic with segmented 30sec audios length\n",
        "folder_path_whisper_ad_seg = \"/content/drive/MyDrive/Alzheimer_transcripts/transcriptions/whisper_seg/ad\"\n",
        "folder_path_whisper_cn_seg = \"/content/drive/MyDrive/Alzheimer_transcripts/transcriptions/whisper_seg/cn\"\n",
        "\n",
        "\n",
        "\n",
        "# # Liste tous les fichiers dans les 2 dossiers\n",
        "# def list_files(folder_ad, folder_cn):\n",
        "#   files = []\n",
        "#   for data in [folder_ad, folder_cn]:\n",
        "#       files.extend(os.listdir(data))    \n",
        "#   return files   \n",
        "\n",
        "# files_whisperX = list_files(folder_path_whisperX_ad, folder_path_whisperX_cn)\n",
        "# print(\"taille whisperX files : \", len(files_whisperX))\n",
        "# files_whisperX_seg = list_files(folder_path_whisperX_ad_seg, folder_path_whisperX_cn_seg)\n",
        "# print(\"taille whisperX_seg files : \",len(files_whisperX_seg))\n",
        "# files_whisperX_seg_ws = list_files(folder_path_whisperX_ad_ws_seg, folder_path_whisperX_cn_ws_seg)\n",
        "# print(\"taille whisperX_seg_ws files : \",len(files_whisperX_seg_ws))\n",
        "# files_whisperX_ws = list_files(folder_path_whisperX_ad_ws, folder_path_whisperX_cn_ws)\n",
        "# print(\"taille whisperX_ws files : \",len(files_whisperX_ws))\n",
        "\n",
        "\n",
        "# files_whisper = list_files(folder_path_whisper_ad, folder_path_whisper_cn)\n",
        "# print(\"taille whisper files : \", len(files_whisper))\n",
        "# files_whisper_seg = list_files(folder_path_whisper_ad_seg, folder_path_whisper_cn_seg)\n",
        "# print(\"taille whisper_seg files : \", len(files_whisper_seg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d6d201e",
      "metadata": {
        "id": "6d6d201e"
      },
      "outputs": [],
      "source": [
        "def from_json_to_dict(folder_ad, folder_cn):\n",
        "    data_ad = []\n",
        "    data_cn = []\n",
        "    for dir_path in [folder_ad, folder_cn]:\n",
        "        for file_name in os.listdir(dir_path):\n",
        "            if file_name.endswith('.json'):\n",
        "                file_path = os.path.join(dir_path, file_name)\n",
        "                with open(file_path, 'r') as f:\n",
        "                    data = json.load(f)\n",
        "                    if dir_path == folder_ad:\n",
        "                        data_ad.append(data)\n",
        "                    elif dir_path == folder_cn:\n",
        "                        data_cn.append(data)\n",
        "    return data_ad, data_cn             \n",
        "\n",
        "                \n",
        "whisperX_data_ad, whisperX_data_cn = from_json_to_dict(folder_path_whisperX_ad, folder_path_whisperX_cn)\n",
        "whisperX_seg_data_ad, whisperX_seg_data_cn = from_json_to_dict(folder_path_whisperX_ad_seg, folder_path_whisperX_cn_seg)\n",
        "whisperX_seg_ws_data_ad, whisperX_seg_ws_data_cn = from_json_to_dict(folder_path_whisperX_ad_ws_seg, folder_path_whisperX_cn_ws_seg)\n",
        "whisperX_ws_data_ad, whisperX_ws_data_cn = from_json_to_dict(folder_path_whisperX_ad_ws, folder_path_whisperX_cn_ws)\n",
        "\n",
        "\n",
        "whisper_seg_data_ad, whisper_seg_data_cn = from_json_to_dict(folder_path_whisper_ad_seg, folder_path_whisper_cn_seg)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "whisper_data_ad, whisper_data_cn = from_json_to_dict(folder_path_whisper_ad, folder_path_whisper_cn)"
      ],
      "metadata": {
        "id": "zHk7mTKnKYTD"
      },
      "id": "zHk7mTKnKYTD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from random import choice\n",
        "\n",
        "print(\"\\nexemple d'une data ad avec whisperX :\\n \", choice(whisperX_data_ad))\n",
        "print(\"\\nexemple d'une data cn avec whisperX :\\n \", choice(whisperX_data_cn))\n",
        "\n",
        "print(\"\\nexemple d'une data ad avec whisperX_ws :\\n \", whisperX_ws_data_ad[1])"
      ],
      "metadata": {
        "id": "gakJZ4yaItVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78dae449-d0bd-4f6a-8443-8244f65f2e3b"
      },
      "id": "gakJZ4yaItVp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "exemple d'une data ad avec whisperX :\n",
            "  {'text': \"Just to take a look at this picture and tell me everything that you see going on in the picture. Tell me everything that you see happening. Now, the girl's cooking, the girl's cooking, the boy's cooking and he's still a fellow when the cookies are spilled. These bills produce water. Worshindoishes. There's Worshindoishes drying them. They run over the sinks running over. Your feet can't go water. There must be a path out back. Fires, trees. I don't know what else. Water on the floor. Is that everything then? Yeah.\", 'label': 1}\n",
            "\n",
            "exemple d'une data cn avec whisperX :\n",
            "  {'text': \"I'm going to go ahead and show you all of the action. There's a boy reaching, he's on a stool, reaching for a cookie, and the stool is ready to fall over. He's got one hand in the cookie jar, and he's got a cookie in the left hand. There's a girl standing beside him. Go ahead. And she's reaching for the coquina gas in her hand, and she has her right finger up to her lip. There's a woman standing at the sink, drying dishes, and the sink is always flowing with water onto the floor. You just want the action. Mm hmm. Awesome. Good, thank you.\", 'label': 0}\n",
            "\n",
            "exemple d'une data ad avec whisperX_ws :\n",
            "  {'text': \"Tell me everything that's going on. .. Well, . the kids are . working on the corner. We're grading, I think they are going to . get .. some cookies from the cookie jar and the mother does not see it because she's inside . drying the clothes. And . the kids then just, I guess, did a picture that the mother that's working hard and the kids were playing and all of a sudden somebody .. turned over a dish and all over the floor except that it did not splash from the sink, but not . from the hot water. long silence No, that's not... I'm trying to get too much out of it. That's okay. Is there anything else? . One of the kids is going to get a crack on my head. . And maybe has a... long silence Yes, it's . so... sometimes I see it very clearly and . other times I see a weak image, so to speak. And sometimes I just... What is it, you know? Well, is there anything else that you can think of? Mostly, I have not so much trouble in . looking at that thing as an image, long silence but .. not getting any of the yours. Was there anything else in that picture you want to tell me or do you think you've told me everything? Okay, thank you. All\", 'label': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd4c6b38",
      "metadata": {
        "id": "dd4c6b38"
      },
      "outputs": [],
      "source": [
        "#delete des keys autre que 'text' et 'label'\n",
        "keys_to_keep = ['text', 'label']\n",
        "\n",
        "def delete_keys(d, keys_to_keep):\n",
        "    for key in list(d.keys()):\n",
        "        if key not in keys_to_keep:\n",
        "            del d[key]\n",
        "\n",
        "for data in (whisperX_data_ad + whisperX_data_cn + \\\n",
        "             whisperX_seg_data_ad + whisperX_seg_data_cn + \\\n",
        "             whisperX_seg_ws_data_ad + whisperX_seg_ws_data_cn +\\\n",
        "             whisperX_ws_data_ad + whisperX_ws_data_cn +\\\n",
        "             whisper_seg_data_ad + whisper_seg_data_cn +\\\n",
        "             whisper_data_ad + whisper_data_cn):\n",
        "    delete_keys(data, keys_to_keep)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41335178",
      "metadata": {
        "id": "41335178"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eaa6fac",
      "metadata": {
        "id": "6eaa6fac"
      },
      "outputs": [],
      "source": [
        "# nous avons 6 types de données différentes, on leur attribue un numéros pour la lisibilité des variables:\n",
        "# 0 : whisper\n",
        "# 1 : whisper_seg\n",
        "\n",
        "# 2 : whisperX\n",
        "# 3 : whisperX_seg\n",
        "# 4 : whisperX_seg_ws\n",
        "# 5 : whisperX_ws\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_0 = whisper_data_ad + whisper_data_cn\n",
        "data_1 = whisper_seg_data_ad + whisper_seg_data_cn \n",
        "data_2 =whisperX_data_ad + whisperX_data_cn\n",
        "data_3 = whisperX_seg_data_ad + whisperX_seg_data_cn\n",
        "data_4 = whisperX_seg_ws_data_ad + whisperX_seg_ws_data_cn\n",
        "data_5 = whisperX_ws_data_ad + whisperX_ws_data_cn\n",
        "\n",
        "texts_0, labels_0 = zip(*[(d['text'], d['label']) for d in data_0])\n",
        "texts_1, labels_1 = zip(*[(d['text'], d['label']) for d in data_1])\n",
        "texts_2, labels_2 = zip(*[(d['text'], d['label']) for d in data_2])\n",
        "texts_3, labels_3 = zip(*[(d['text'], d['label']) for d in data_3])\n",
        "texts_4, labels_4 = zip(*[(d['text'], d['label']) for d in data_4])\n",
        "texts_5, labels_5 = zip(*[(d['text'], d['label']) for d in data_5])\n",
        "\n",
        "x_train_0, x_test_0, y_train_0, y_test_0 = train_test_split(texts_0, labels_0, random_state = 0, stratify = labels_0)\n",
        "x_train_1, x_test_1, y_train_1, y_test_1 = train_test_split(texts_1, labels_1, random_state = 0, stratify = labels_1)\n",
        "x_train_2, x_test_2, y_train_2, y_test_2 = train_test_split(texts_2, labels_2, random_state = 0, stratify = labels_2)\n",
        "x_train_3, x_test_3, y_train_3, y_test_3 = train_test_split(texts_3, labels_3, random_state = 0, stratify = labels_3)\n",
        "x_train_4, x_test_4, y_train_4, y_test_4 = train_test_split(texts_4, labels_4, random_state = 0, stratify = labels_4)\n",
        "x_train_5, x_test_5, y_train_5, y_test_5 = train_test_split(texts_5, labels_5, random_state = 0, stratify = labels_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0c7074a",
      "metadata": {
        "id": "a0c7074a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb10ff99",
      "metadata": {
        "id": "bb10ff99",
        "outputId": "a5312aea-05e8-4e35-e4ff-744c1800a2f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_text) (2.11.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.30.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.19.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.21.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (15.0.6.1)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (23.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.11.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (23.1.21)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (4.5.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.51.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.16.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.25.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (6.0.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "#!pip install tensorflow_hub\n",
        "!pip install tensorflow_text\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "#bert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
        "# bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "# bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "356a85da",
      "metadata": {
        "scrolled": true,
        "id": "356a85da"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5bdd5a2",
      "metadata": {
        "id": "a5bdd5a2"
      },
      "outputs": [],
      "source": [
        "# # Bert layers\n",
        "# text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "# preprocessed_text = bert_preprocess(text_input)\n",
        "# outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "# # Neural network layers\n",
        "# l = tf.keras.layers.Dropout(0.01, name=\"dropout\")(outputs['pooled_output'])\n",
        "# l2 = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
        "\n",
        "# # Use inputs and outputs to construct a final model\n",
        "# model = tf.keras.Model(inputs=[text_input], outputs = [l2])\n",
        "\n",
        "def build_classifier_model():\n",
        "  bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\", name='preprocessing')\n",
        "  bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\", trainable=True, name='BERT_encoder')\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = bert_preprocess\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = bert_encoder\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.1)(net)\n",
        "  net = tf.keras.layers.Dense(1, activation=\"sigmoid\", name='classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f50b669e",
      "metadata": {
        "id": "f50b669e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de77ef7e-ca50-459b-8446-3002923e0a56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " preprocessing (KerasLayer)     {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 128),                                                          \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'pooled_output': (  109482241   ['preprocessing[0][0]',          \n",
            "                                None, 768),                       'preprocessing[0][1]',          \n",
            "                                 'default': (None,                'preprocessing[0][2]']          \n",
            "                                768),                                                             \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)]}                                               \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 768)          0           ['BERT_encoder[0][13]']          \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 1)            769         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,010\n",
            "Trainable params: 109,483,009\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#model_0 = build_classifier_model()\n",
        "#model_1 = build_classifier_model()\n",
        "model_2 = build_classifier_model()\n",
        "model_3 = build_classifier_model()\n",
        "model_4 = build_classifier_model()\n",
        "#model_5 = build_classifier_model()\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tf-models-official\n",
        "\n",
        "from official.nlp import optimization\n",
        "\n",
        "# loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metrics = tf.metrics.BinaryAccuracy()\n",
        "\n",
        "epochs = 20\n",
        "steps_per_epoch = 200\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "init_lr = 3e-5\n",
        "# METRICS = [\n",
        "#       tf.keras.metrics.Accuracy(name='accuracy'),\n",
        "#       tf.keras.metrics.Precision(name='precision'),\n",
        "#       tf.keras.metrics.Recall(name='recall')\n",
        "# ]\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')\n"
      ],
      "metadata": {
        "id": "wmli2cMtNS-D"
      },
      "id": "wmli2cMtNS-D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training models 2\n",
        "model_2.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=metrics)\n",
        "model_2.fit(x_train_2, y_train_2, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA56eOu1Nb_K",
        "outputId": "341826e6-5246-4740-ee9e-b610f823a661"
      },
      "id": "AA56eOu1Nb_K",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4/4 [==============================] - 45s 962ms/step - loss: 0.7454 - binary_accuracy: 0.5081\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 3s 833ms/step - loss: 0.7175 - binary_accuracy: 0.4919\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 3s 832ms/step - loss: 0.7140 - binary_accuracy: 0.5161\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 4s 890ms/step - loss: 0.6985 - binary_accuracy: 0.5242\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 3s 839ms/step - loss: 0.6918 - binary_accuracy: 0.5242\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 3s 844ms/step - loss: 0.6650 - binary_accuracy: 0.5968\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 4s 897ms/step - loss: 0.6641 - binary_accuracy: 0.6371\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 3s 842ms/step - loss: 0.6565 - binary_accuracy: 0.5726\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 3s 844ms/step - loss: 0.6353 - binary_accuracy: 0.6129\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 4s 881ms/step - loss: 0.6168 - binary_accuracy: 0.7097\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 4s 868ms/step - loss: 0.6080 - binary_accuracy: 0.6613\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 4s 888ms/step - loss: 0.5656 - binary_accuracy: 0.7177\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 4s 857ms/step - loss: 0.5458 - binary_accuracy: 0.7500\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 4s 953ms/step - loss: 0.4942 - binary_accuracy: 0.7823\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 4s 851ms/step - loss: 0.4898 - binary_accuracy: 0.8145\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 3s 870ms/step - loss: 0.4432 - binary_accuracy: 0.8306\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 4s 906ms/step - loss: 0.3995 - binary_accuracy: 0.8468\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 4s 934ms/step - loss: 0.3767 - binary_accuracy: 0.8387\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 4s 956ms/step - loss: 0.3303 - binary_accuracy: 0.8871\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.3222 - binary_accuracy: 0.9435\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f272e913610>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training models 3\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')\n",
        "model_3 = build_classifier_model()\n",
        "model_3.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=metrics)\n",
        "model_3.fit(x_train_3, y_train_3, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etkZN8qdTenw",
        "outputId": "87638ae3-a97d-4f2b-ebee-ffde50eb5321"
      },
      "id": "etkZN8qdTenw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "12/12 [==============================] - 53s 976ms/step - loss: 0.6950 - binary_accuracy: 0.6260\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 12s 991ms/step - loss: 0.5918 - binary_accuracy: 0.6979\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 11s 940ms/step - loss: 0.5273 - binary_accuracy: 0.7526\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 11s 904ms/step - loss: 0.4369 - binary_accuracy: 0.8411\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 11s 918ms/step - loss: 0.3368 - binary_accuracy: 0.9036\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 11s 900ms/step - loss: 0.2674 - binary_accuracy: 0.9193\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 11s 901ms/step - loss: 0.1825 - binary_accuracy: 0.9531\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 11s 911ms/step - loss: 0.1326 - binary_accuracy: 0.9635\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 11s 916ms/step - loss: 0.1257 - binary_accuracy: 0.9661\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 11s 916ms/step - loss: 0.0827 - binary_accuracy: 0.9766\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 11s 888ms/step - loss: 0.0334 - binary_accuracy: 0.9922\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 11s 904ms/step - loss: 0.0179 - binary_accuracy: 0.9974\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 11s 889ms/step - loss: 0.0198 - binary_accuracy: 0.9948\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 11s 923ms/step - loss: 0.0078 - binary_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 11s 895ms/step - loss: 0.0154 - binary_accuracy: 0.9974\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 12s 994ms/step - loss: 0.0241 - binary_accuracy: 0.9896\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 11s 945ms/step - loss: 0.0482 - binary_accuracy: 0.9844\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 11s 917ms/step - loss: 0.0137 - binary_accuracy: 0.9948\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 11s 904ms/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 11s 897ms/step - loss: 7.7778e-04 - binary_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f272f29daf0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training models 4\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')\n",
        "model_4 = build_classifier_model()\n",
        "model_4.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=metrics)\n",
        "model_4.fit(x_train_4, y_train_4, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5g6bZGfTg4s",
        "outputId": "1ba4a0cc-81da-4643-ee99-68ecf0519355"
      },
      "id": "E5g6bZGfTg4s",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "12/12 [==============================] - 36s 907ms/step - loss: 0.6448 - binary_accuracy: 0.8203\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 11s 903ms/step - loss: 0.4552 - binary_accuracy: 0.7995\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 11s 933ms/step - loss: 0.2211 - binary_accuracy: 0.9271\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 11s 915ms/step - loss: 0.1241 - binary_accuracy: 0.9557\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 11s 928ms/step - loss: 0.0882 - binary_accuracy: 0.9661\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 11s 895ms/step - loss: 0.0619 - binary_accuracy: 0.9818\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 11s 909ms/step - loss: 0.0388 - binary_accuracy: 0.9870\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 11s 921ms/step - loss: 0.0317 - binary_accuracy: 0.9818\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 11s 909ms/step - loss: 0.0300 - binary_accuracy: 0.9896\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 11s 912ms/step - loss: 0.0238 - binary_accuracy: 0.9896\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 11s 922ms/step - loss: 0.0202 - binary_accuracy: 0.9922\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 11s 889ms/step - loss: 0.0204 - binary_accuracy: 0.9922\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 11s 912ms/step - loss: 0.0209 - binary_accuracy: 0.9896\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 11s 900ms/step - loss: 0.0169 - binary_accuracy: 0.9922\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 11s 883ms/step - loss: 0.0207 - binary_accuracy: 0.9922\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 11s 893ms/step - loss: 0.0313 - binary_accuracy: 0.9844\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 11s 920ms/step - loss: 0.0197 - binary_accuracy: 0.9948\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 11s 907ms/step - loss: 0.0169 - binary_accuracy: 0.9922\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 11s 915ms/step - loss: 0.0184 - binary_accuracy: 0.9922\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 11s 896ms/step - loss: 0.0230 - binary_accuracy: 0.9870\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f26316d6fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T4oIPlSaTnWC"
      },
      "id": "T4oIPlSaTnWC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0I-ah1iqTszA"
      },
      "id": "0I-ah1iqTszA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TMfESJEkTvcl"
      },
      "id": "TMfESJEkTvcl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "model_2.evaluate(x_test_2, y_test_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wGVLr85NoQl",
        "outputId": "b08ef516-c118-4f87-82f8-01ab555b8fb2"
      },
      "id": "_wGVLr85NoQl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 2s 118ms/step - loss: 0.5516 - binary_accuracy: 0.7143\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5516329407691956, 0.7142857313156128]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.evaluate(x_test_3, y_test_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu2HesnYsSHB",
        "outputId": "7810966d-76ba-4697-b435-cb78f1f6a86e"
      },
      "id": "Vu2HesnYsSHB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 2s 251ms/step - loss: 1.6139 - binary_accuracy: 0.7209\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6138954162597656, 0.7209302186965942]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.evaluate(x_test_4, y_test_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPqwboZhsS68",
        "outputId": "9aa43b92-04cf-468b-fe45-bbe71939c688"
      },
      "id": "HPqwboZhsS68",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 3s 290ms/step - loss: 1.5625 - binary_accuracy: 0.7752\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5625059604644775, 0.7751938104629517]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted_2 = model_2.predict(x_test_2)\n",
        "y_predicted_2 = np.round(y_predicted_2).flatten()\n",
        "\n",
        "y_predicted_3 = model_3.predict(x_test_3)\n",
        "y_predicted_3 = np.round(y_predicted_3).flatten()\n",
        "\n",
        "y_predicted_4 = model_4.predict(x_test_4)\n",
        "y_predicted_4 = np.round(y_predicted_4).flatten()\n",
        "\n",
        "\n",
        "cm_2 = confusion_matrix(y_test_2, y_predicted_2)\n",
        "cm_3 = confusion_matrix(y_test_3, y_predicted_3)\n",
        "cm_4 = confusion_matrix(y_test_4, y_predicted_4)\n",
        "\n",
        "# Créer une grille de subplots pour afficher les matrices de confusion\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 3))\n",
        "\n",
        "# Afficher chaque matrice de confusion dans un subplot différent\n",
        "sn.heatmap(cm_2, ax=axes[0], annot=True, cmap=\"Blues\", fmt='g')\n",
        "sn.heatmap(cm_3, ax=axes[1], annot=True, cmap=\"Blues\", fmt='g')\n",
        "sn.heatmap(cm_4, ax=axes[2], annot=True, cmap=\"Blues\", fmt='g')\n",
        "\n",
        "axes[0].set_xlabel('Prédiction')\n",
        "axes[0].set_ylabel('Réel')\n",
        "axes[0].set_title('Matrice de confusion 2 : données de whisperX')\n",
        "\n",
        "axes[1].set_xlabel('Prédiction')\n",
        "axes[1].set_ylabel('Réel')\n",
        "axes[1].set_title('Matrice de confusion 3 : données de whisperX_seg')\n",
        "\n",
        "axes[2].set_xlabel('Prédiction')\n",
        "axes[2].set_ylabel('Réel')\n",
        "axes[2].set_title('Matrice de confusion 4 : données de whisperX_seg_ws')\n",
        "\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "aw1V23xaN6_i",
        "outputId": "da4b85f6-2d47-4afe-88b2-e4c699db1bf6"
      },
      "id": "aw1V23xaN6_i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 341ms/step\n",
            "5/5 [==============================] - 1s 302ms/step\n",
            "5/5 [==============================] - 1s 304ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x216 with 6 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABXAAAADQCAYAAACuq0nnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZgcZbn38e89CfsekBjWsCMiICKCCLIqIAoqoAgaBIy44IqC6BHEowJ6VN7jUQy7giyiCG4ooiwqiyCoCCgIYc3CEiCYAFnu94+qkGac6Vm6eqpn5vvhqovuqu6qu7or/Zt6quqpyEwkSZIkSZIkSZ2nq+4CJEmSJEmSJEk9swFXkiRJkiRJkjqUDbiSJEmSJEmS1KFswJUkSZIkSZKkDmUDriRJkiRJkiR1KBtwJUmSJEmSJKlD2YA7TETEwRHx6yFYTkbEhu1eTn9FxA4RcXdEPBMR+7Uwn19GxKQqaxsKQ/19RMRGEfHXiFhvCJY1NSJ2b+P8D42I3zeZPiy3CUkvZj6aj0O0PPNR0rBlVo6+rIyIieX3MXYIl7lDRPwpIsYNwbLauq1FxAkRcV6T6X+PiJ3btXypJzbgtqD8A/v5iFit2/hbyx+Uif2YR79+WDPz/Mx8Q2sVD0snAt/KzOUz8yeDnUlm7pWZ51ZYFwAR8amIuD0iZkfEfRHxqaqXMVQiYiXgdGD/zLyv7nrarV3bRDMRsWZEzIqI1zWMW7sc95qhrEVqJ/NxSHR6Pn48Iu6NiKcj4pGI+MZQ7kRWyXxsP/NRo5FZOSQ6OisXiYglI+LOiHioXctot4hYG/gy8KbMfKLuetotM1+emVcP5TIj4pXl31UbNox7VUQ82Z/fCw1/NuC27j7goEVPIuIVwLJVLmC47vBUZF3g73UX0UQA7wFWAfYEPhwR76y3pMHJzKcyc+fM/GfdtYxEETE2Mx8GjgHOiIily0nfBc7OzBvrq05qC/OxvTo9Hy8Hts7MFYHNgS2Bj9Rb0uCYj+1lPmqUMyvbq9OzcpFPAY/WXUQrMvPBzHx9Zs6su5aRqMzKW4FvAadHYQngLODzmTm11gI1JGzAbd33KRrwFpkEfK/xBRHxpvJI6tMR8WBEnNAw+dry/0+Wl3ZsX17a9ofybJXHgRO6X+4WES+PiCsj4omImBERx5XjuyLi2Ij4V0Q8HhEXN7uEoTyDdFp5dsxh3aYtFRFfi4gHymWcFhHLNJnX+8ojh7Mj4o6I2Loc/7KIuLo8MvT3iHhLw3vOiYj/i4ifl++7MSI2KKf9C1gf+Gn52SwV3S4rjIZLGyJi6Yg4r1zvJ6O4fGN8Oe3qiDii4TP6XETcHxEzI+J75dk1jUexJ5Xr/VhEfLa3dc7MUzLzz5k5PzP/AVwG7NDb6/vSx/exUlnro2Xtn4uIrnLaoRHx+/L7mhXF2cB7Nbz36oj4YrldzY6IX0fD0f6I2C4i/lh+bn+JhstByuWeWdb1cET8d0SMKadtGBHXRMRT5Wd1UZN1e3dZ9+PdP9OBbLfl8t5ePt6h/L7eVD7fLSJu6/b6Zp/Jom2i1/Uo5/+RKM4keywivrrocy+nH1Zu97Mi4lcRsW63934oIu4G7i5Hnw5MA46P4lKsTYDP9fa5ScOY+bj49aMxH/+VmU8uKgdYCAz6Usc+vg/zkdGbj+V3fG8svhrq4H7W8IaI+Ee5bt8u1/OIvpYnVcysXPz6UZeV5XvWAw4BvtLsdX2JiDHl5/1YRNwLvKnb9DUi4vLyO78nIt7X7XO4uFyX2eXnvE3D9KkRcXQUXQk9FREXxeKDbUTEPhFxW/m5/TEitui23B9FkdH3RcRHGqZtGxE3l9v2jIj4epP1q2RbK7+3V5WPDy6/r5eXzw+PiMYztZfs4zPZvdl6NGwPk8u6p0XE0Q3z6PXfW8N7D4+IB4Dflm/7AjABmAwcBzxD0ajbVEQcE8XfKrOjyL7d+qqhnP6eWPw3yn91/zfUw3KWjoi5Uf4tFRGfjYj5EbFi+fyLEfHN8vHeUfxbn13WdnRv81UpMx0GOQBTgd2BfwAvA8YAD1Ec6UtgYvm6nYFXUDSYbwHMAPYrp00sXzu2Yb6HAvOBo4CxwDLluN+X01eg+AP3k8DS5fPXlNM+CtwArAUsRXH2wgW91L9nWcvmwHLAD8paNiynf4PiDJpx5TJ+Cnyll3kdADwMvJpiR23D8nNYAriH4sdlSWBXYDawSfm+c4DHgW3LdT0fuLD7Z9zk+QnAeeXj95c1Llt+F68CViynXQ0cUT4+rKxpfWB54MfA97t9H6eXn/uWwHPAy/qxPQRwK3Bkk9f8FXjXIL+P71E0EK9Q1vlP4PCGbWYe8L5y3T8APAJEw/r/C9i4XK+rgZPKaWuW38HeFNvoHuXzl5TTL6XYjpYDVgduAt5fTrsA+Gz5vqWB1/WybptRhMtOFNvl1ym28d0Hsd2eCPxv+fi4cr1Obph26gA+kyP6Wo/yO/gdxb+DdcrPfdH79qXYll5Gsf1+Dvhjt/deWb53mYbxGwBPAbOAXev+LXNwqHrAfGyc16jNR+BdwNPl+x4FtmzyWvPRfIQB5mP52T/N4n83E4CX91UDsFr5vreV0z5afiZH1P376TB6BszKxnmN5qz8GfDW8nt+qI9t5kl6z5MjgbuAtcvP/HeN2wZFY/+3y+98K4pc3rXhc3iWIu/GUDQm39Dtc7sJWKOc952U+7zAK4GZwGvK904qX78UxTZ7C/D58vtbH7gXeGP53uuBd5ePlwe2G4Jt7XvAJ8vHUyiy8gMN0z4+gM9k92br0bA9XFDW/Yryc+8z4xve+73yvY1ZuUO5LTwNbNqP35pNgAeBNRrmvUE/alj0N8rryu/vaxRZuXsfy7sWeHv5+NflZ7xXw7S3lo+nATuWj1ehuHKr9t/mTh5qL2A4DywO3c+V/6D3pPhjdCwNodvD+74JfKN8vOgfZvfQfaDbew5lcegeBNzay7zvBHZreD6h/Ec2tofXnkW5k1I+37isZUOK4Pz3on/Y5fTtgft6We6vgI/2MH5HYDrQ1TDuAuCE8vE5wBkN0/YG7ur+GTd5fgKLQ/cw4I/AFj3UcTWLQ/cq4IMN0zZZ9Bk1fB9rNUy/CXhnP7aHLwB/AZYa5PbU7PsYAzwPbNYw/f3A1Q3bxz0N05Yt3/vShvX/XMP0DwJXlI+Pofyjo9v3OQkYT/FHR2NgHAT8rnz8PYrgW6uPdfs8L/5jarlyfRaF10C2292Av5aPrwCOoAxT4BrgbQP4TI7oaz3K9+zZ7bO7qnz8S8pGgvJ5FzAHWLfhvf+xA1pua3cC9/e0jg4Ow33AfGycl/kIGwFfpPz9HcT2ZD72b7sddflYfl5PAm9v/C76qoHijMfrG6YFxc6tDbgOQzZgVjbOa1RmJUXD7S/LxzvTRwNuH9vTb2k4kQh4w6Jtg6JRdwGwQsP0rwDnNHwOv2mYthkwt9vndkjD81OA08rH3wG+2K2WfwCvp2jU7b4tfoaiexwoGvO+AKzWx7pVua0dDlzesL0fQZnDFNmz9QA+k92brUfD9rBpw7hTgDP7+vfW8N71e1iHlYDHgD/0c9vYkKKRfXdgiW7TmtXweRoO4FD8vfDC3yhNlvdF4P+V85hO0Uh8EsXBg7nAquXrHqD4m23FwW73o22wC4VqfJ/iLJND6XbJC0BEvCYifldeNvAUxdGx1bq/rpsHm0xbm+IoRk/WBS4tL194kuIf5AKKHY3u1ui2nPsbHr+E4h/oLQ3zuqIcP5Ca1gAezMyF3ZazZsPz6Q2P51ActRqM71OE/4XlJQqnRNEvTE81Na7r/RQ/Lo2f0YBqiogPU+wMvCkznxtM8TT/PlajOALdve4eP8fMnFM+XL6n6bx4ndYFDlj0PZff9esofrzXLZc7rWHadynONAL4NEVo3lReVvKiy1l6W7fM/DfF0fJFBrLdXg9sHMUlTVtR/Jtbu7xMY1sWX0rWn89kkb7Wo/v3skZD3ac21P1EOZ81e3nvIsdSrP9MwEtFNJKZj6M8HwEy826KPgi/PdDCG+oyH83H/1B+Xu+g+O2YFsVl1Jv2o4bun3tSnPko1cGsHIVZGRHLUTTmVdU/fLPvYw3gicyc3W16s89x6Xhx/8nNsvKT3bJy7XKZ6wJrdJt2HIs/q8MpGmPviqLLin0GsW4D3dauAXaMiAkUB4EvBnaI4iZgKwGN3Q319Zks0td6NMvKvv699fRv+X/K9Vgr+nH/ncy8B/gYRaP0zIi4MCL6U0P3rJzDi/9G6c01FAcktgb+RnFg6vXAdhQHkBfN4+0UB13uj6Ibo+37Me9RzQbcCmTm/RQd0O9NcQlFdz+gOKV/7cxcCTiN4g9IKI6q9DjbJot8kOLyg96m7ZWZKzcMS2dxc4juplH8uC6yTsPjxyiOjry8YT4rZWZvgfggxWVv3T1CsfPQuK2tQ3GJzGD8mxd37P/SRQ8yc15mfiEzNwNeC+zDi/uUaqxp3W71zKe4LGPAyp2ZYymOXLXyx39f38c8/rPuwX6OjR6kOMOocZtZLjNPKqc9R3E0cdG0FTPz5QCZOT0z35eZa1AcPft2NNwVs7d1i4hlgVW71dCv7bYMjlsojuTdnpnPUxwt/wTwr8x8bKAfQD/Wo/v38khD3e/vVvcymfnHxtk3LisiNqO4UcERFGF/XERsNNCapeHAfHxhuaMyH7sZS8+fQ3+Yj+Zjsxp/lZl7UDSs30Vx6XJfNUyjuFx00bKj8bk0lMzKF5Y72rJyI4qzLK+LiOkU3/2EiJheNiYOVLPv4xFgXESs0G16VVn5pW7bzLKZeUE57b5u01bIzL2hOMCbmQdRHPw8GbikbNgeyLoNaFsrGzPnUHQxcm1mPk3RUDuZ4iz1hT29r5l+rEezrOzr31v3rNwdeAtFJn+A4kBlr/1UN9T4g8x8HYu7aDm5HzV0z8plePHfKL35I8WZ6W8FrsnMO8r13puicXdRTX/KzH0pPrefUDSmqwkbcKtzOMWlYP/uYdoKFEe8no2IbSmOsC7yKMWNPXoL0Z78jOLH/WNRdNi9QkS8ppx2GvClKG/SEBEviYh9e5nPxcChEbFZucNw/KIJ5Q/X6cA3ImL1cl5rRsQbe5nXGcDREfGqKGxY1nAjxQ/kpyNiiShu/vFm4MIBrG+j24B3lvPaBth/0YSI2CUiXhHFDUSeptih6+kH+ALg4xGxXkQsD3wZuCgz5w+0mChulPFlYI/MvHcQ69Oo2fexoJz+pfL7Xpdih+y8FpdJOY83R8Qbo+j8fumI2Dki1srMaRT91vxPRKwYRSfnG0TE6wEi4oCIWPSjPosiDHr6zC8B9omI10XEkhR98TX+/gxku4Xih//DLA6Aq7s9H5B+rMenImKViFibYsd40U1cTgM+E4s7vl8pIg5ospwu4EzglMy8KzP/SnF5yZRy51EaiczH0ZmPRzR8PptRXDJ51YDXqmA+mo+9vW98ROwbxY7ycxR99S2qr1kNPwdeERH7RXE21YdoaMiRamBWjr6svJ2iYW+rcjiCohF4K5qfQd2bi4GPRMRaEbEKxQlGAGTmgxSNal8ps2wLim2uiqw8HTgyijPFIyKWi+LGeytQdB8xO4obaC1TZunmEfFqgIg4JCJeUm4vi2582tNnXuW2BtVnZV/r8V8RsWyZR+/lxVnZ74wvs24KRT+9j2XmLyjObv1GH/VtEhG7RsRSFP36zuXFWdlbDZdQ/B302vJvlBNYfPCoVw0HlD/E4s/0jxRXD1xTLmfJKG4it1JmzqP4NzfgxvPRxgbcimRxt+Wbe5n8QeDEiJhN0Y/IxQ3vmwN8CfhDFKetb9ePZc2muJHGmymOFt0N7FJOPpXiCO2vy+XdQNH3TE/z+SVFH0q/peiI/bfdXnJMOf6GiHga+A3FkZSe5vXDcj1+QNGx/E+AceXZH28G9qI4OvZt4D2ZeVdf69mL/6I4OjuLop+ZHzRMeynFj8zTFKf+X0NxKUx3Z5Xjr6U42v0sxRG4wfhviqNQf4ri7qbPRMRpvb04issPD+5pWj++j6MojhrfC/yeYt3PGmTdjct9kOJGH8dR/BH4IMUZMIt+H95D0Wn5HRSf+yUUZ7lAcaOBGyPiGYrt7qM9NWRn5t8pfsB/QHEkbxYvvlSx39tt6RqKP2av7eX5QPW1HpdRhNBtFDt9Z5brdSnF0csLy38jt1Ns6735KMVR/1Maxn2RYtv1ztcakczHUZuPOwB/i4h/A78oh+N6e7H5aD4yuHzsomiwf4Sii4TXU5yR1LSG8mzkA8rlPU7Rt+HNFI3A0pAzK0dfVmbm/CyucpiemdMpfsMWls8X9PSecl9zx15meTpFFxB/Af7Mf57NfRDFGb+PUNyE8/jM/M1A6+5hPW6muCnmtyg+13sougNZdJB1H4pG6fsovsMzKLoqgKLf57+XGXMqRV/Bc3tYRmXbWqnqrOxrPa4p67sK+Fpm/rocP9CM/zJFH8/nN4z7GLBXROzR5H1LUfRB+xjFv/nVKQ6sN62h/BvlKIoDJtMoDpLOpH9ZeQ1FV1M3NTzv/hm/G5hafmdHAj3+HajFFt1tVpLUg4hIYKPychtJksTIysfyDOCHgIMz83d11yNJGv6i6ArjPoobhw34aqZOU55x/iRF9t9Xdz2jkWfgSpIkSRpVougaY+XyktLjKC4LvaHmsiRJ6hgR8eay+4flgK9R3JRsar1VjV424EqSJEnqWA3dVHUferuUuD+2p7jr/WMUl2jv19Olu6NV2bh9SUTcFRF3RsT2ETEuIq6MiLvL/69Sd52SJIiIdZpk5Tp9z6FX+1J0u/EIxY333pmZGRG/7GVZvXaXpdbZhYIkSZIk6QURcS5wXWaeUd68ZlmKM5WfyMyTIuJYYJXMPKbWQiVJGiVswJUkSZIkARARK1HcmG79bNhZjIh/ADtn5rSImABcnZnNbhQkSZIqMrbuAnqz3UnX2LKsEeHsSdvUXYJUmZdNWC7aMd9lXvnhXn/z5976rbYsc7T55nX3masaEd6wwep1lyBVYrM12pOp0DxXn73t/94PTG4YNSUzpzQ8Xw94FDg7IrYEbgE+CozPzGnla6YD46uteng58cp7zFUNe3tvaKZq5NhmvRWHfF8Vhm5/tWMbcCVJo0jYJbskSZVpkqtlY+2UXl9Q7CNuDRyVmTdGxKnAsd3mkRFhA6YkaeTrkH3VzqhCkjS6RfQ+SJKkgWktVx8CHsrMG8vnl1A06M4ou06g/P/MttQuSVInaZapQ7i/agOuJKl+XWN6HyRJ0sC0kKuZOR14MCIW9W+7G3AHcDkwqRw3CbisHaVLktRRmmXqEO6v2oWCJKl+NtRKklSd1nP1KOD8iFgSuBd4L8XJPxdHxOHA/cCBrS5EkqSO1yH7qjbgSpLq1yH9CkmSNCK0mKuZeRvQ0514d2tpxpIkDTcdsq9qA64kqX4dclRTkqQRwVyVJKkaHZKpNuBKkurXIaEoSdKIYK5KklSNDslUG3AlSfXrkFCUJGlEMFclSapGh2RqZ3TkIEka3aKr96Gvt0acFREzI+L2buOPioi7IuLvEXFK22qXJKnTtJCrkiSpQbNMHcJc9QxcSVL9xrR0VPMc4FvA9xaNiIhdgH2BLTPzuYhYvaX6JEkaTlrLVUmStEiHZKoNuJKk+rVwWUpmXhsRE7uN/gBwUmY+V75m5qAXIEnScNMhl3tKkjTsdUimeg2NJKl+XWN6HwZnY2DHiLgxIq6JiFdXWK0kSZ2t+lyVJGl0apap/czViFg5Ii4pu/i7MyK2j4hxEXFlRNxd/n+VpmVUsjKSJLUiotchIiZHxM0Nw+R+zHEsMA7YDvgUcHFERFvXQZKkTtEkVyVJ0gA0y9T+5+qpwBWZuSmwJXAncCxwVWZuBFxVPu+VXShIkurX5MhlZk4Bpgxwjg8BP87MBG6KiIXAasCjg65RkqThwjNtJUmqRouZGhErATsBhwJk5vPA8xGxL7Bz+bJzgauBY3oto6UqJEmqQvWXev4E2AUgIjYGlgQeq6haSZI6m10oSJJUjda7UFiP4kSisyPi1og4IyKWA8Zn5rTyNdOB8U3LaGklJEmqQtfY3oc+RMQFwPXAJhHxUEQcDpwFrB8RtwMXApPKs3ElSRr5WshVSZLUoFmmdo3tT5d/Y4Gtge9k5iuBf9Otu4RyX7Xp/qoJLkmqXwt98mXmQb1MOmTQM5UkaTizr1tJkqrRR6b2o8u/h4CHMvPG8vklFA24MyJiQmZOi4gJwMxmy/EMXElS/bzUU5Kk6pirkiRVo8UuFDJzOvBgRGxSjtoNuAO4HJhUjpsEXNZsPp6BK0mqnzuUkiRVx1yVJKka1WTqUcD5EbEkcC/wXoqTai8uuwC8Hziw2QxswJUk1a6rywtCJEmqirkqSVI1qsjUzLwN2KaHSbv1dx424EqS6mdXfZIkVcdclSSpGh2SqTbgSpJq55lCkiRVx1yVJKkanZKpNuBKkmrXKaEoSdJIYK5KklSNTslUG3AlSfXrkMtSJEkaEcxVSZKq0SGZagOuJKl2nXJUU5KkkcBclSSpGp2SqTbgSpJq1ymhKEnSSGCuSpJUjU7JVBtwJUm1i64OuS5FkqQRwFyVJKkanZKpNuBKkmoX0RmhKEnSSGCuSpJUjU7JVBtwJUm165SjmpIkjQSt5mpETAVmAwuA+Zm5TUSMAy4CJgJTgQMzc1ZLC5IkqcN1yr5qZ3TkIEka1bq6unodJEnSwFSUq7tk5laZuU35/FjgqszcCLiqfC5J0ojWLFOHcn/VM3AlSbWzoVaSpOq0KVf3BXYuH58LXA0c044FSZLUKTplX7UzqpAkjW7RZJAkSQPTJFcjYnJE3NwwTO5hDgn8OiJuaZg+PjOnlY+nA+PbvBaSJNWv2b7qEO6vegbuKPLZvTdmhw1WZdaceRx85s0ATN5xIjtttCoLE2bNeZ4v/vwfPPbM8zVXKvXfww9M5atfWHwF34xpD3PQe4/kLQccXGNVGqhOOaop9df8ec9z2clHs2D+PBYuXMD6r9qRbfd9N7875+s8OvVuMpOVX7oWu773kyyx9DJ1lyv16rGZ0zn1K5/nyVmPEwR77PM23rz/uzjntG9w8x+vY+wSY3npGmtz1DEnsNzyK9RdrvqpWa5m5hRgSh+zeF1mPhwRqwNXRsRd3eaREZGtVyoVFsx7niu/eQwL5s8jFyxgnVfuwBZvOuSF6Tf/8DT+df2VvOPrP6qxSqlvjz86ne989QSeevIJAth177ey534HceO1v+FH503hkQencuKp57D+xpvVXar6qVP2VW3AHUV+/rcZXHLLI3x+n01fGHfejQ8y5bqpABz4qjU5bId1OeVXd9dUoTRwa64zkW+eeSEACxYs4PD992S7HXepuSoNVCsdw0fEWcA+wMzM3LzbtE8CXwNekpmPtVSk1GDM2CV4y9Ens8TSy7Bg/nx+cvInWWfzbdjhHe9nyWWWA+APF32Xv/32crbe+x01Vyv1rmvMGA79wMfZYOOXMXfOv/nk+w9mq222Y6tXbce733cUY8aM5XvfPZUfnX8W73n/R+suV/3U6g1XMvPh8v8zI+JSYFtgRkRMyMxpETEBmNl6pVKha+wS7PaRL7PEUsuwcMF8fv31T7HGZtuw2nqb8vj9d/PcnGfqLlHql66usRz8vo+x3kabMnfOv/ncUe9h81e+hrUmbsDH/usUzvp/X6m7RA2QNzHTkLvtwad4+tl5Lxo35/kFLzxeeomu4mIpaZj6659v4qVrrsXqL12j7lI0QC12Cn8OsGf3kRGxNvAG4IFqq5UgIl44s3bhgvksXDCfiHih8TYzmf/880R0xh98Um/GrfoSNtj4ZQAss+xyrLXOejz+2Ey2evX2jBlTnOux8Wav4PFHbasbTlrJ1YhYLiJWWPSYIktvBy4HJpUvmwRc1qbyNQpFBEss1ZirCyBg4cIF3PqTM9l6v8NqrlDqn1VWXY31NipOmltm2eVYY+2JzHr8UdZcZz3WWHtivcVpUEb8TcwiYlOKju7XLEc9DFyemXe2a5kanCN3mshem4/nmecW8KEf/KXucqRB+/1vf8WOu76x7jI0CK00cmXmtRExsYdJ3wA+zQjZwTRXO8/ChQu45ItH8dTMR9h8lzczfv3ij/XfnvU/PPC3P7HKGuvw2gPfV3OVUv/NnP4I993zDzZ+2YsuZuCqX17GDru8oaaqNBgtHjwaD1xazmMs8IPMvCIi/gRcHBGHA/cDB7ZcaE3M1M60cOECrjj5o8x+dBob7/QmVpu4KXf97jLWfMVrWGalcXWXJw3Yo9Mf4f5//YMNNnl53aWoBZ1yQkZbmooj4hjgQorufG8qhwAuiIhjm7zvhQ71Z97003aUph6cdu1U9v32jfzq7zPY/1Weuajhad68edz0h2vZYec96i5FgxBd0fvQv5utvHh+EfsCD2fmiDgqVUWu/vHyC4am2FGkq2sMBx7/bd7z1fOYed8/ePzhqQDsetgnec//nM8qE9bhX3+6tt4ipX6aO3cOJ3/+aA770CdZdrnlXxj/w/POYMyYsbx+971rrE4D1SxX+5KZ92bmluXw8sz8Ujn+8czcLTM3yszdM/OJtq9IGww2U8v3vpCrN//8wvYXO8p0dY1h7898i7f+97k8fv8/mXHP7Txw6+/Z5PVvqbs0acCenTuHb/73Mbz7/Z94Ua5q+Gm6rzqE3Su06wzcw4GXZ+aLrtePiK8DfwdO6ulNjR3qb3fSNV7MP8R+dcdMvn7AKzjj9/fXXYo0YH++8Q+sv/GmrDxu1bpL0SBUcLOVF0TEssBxFJd8jhQt5+o3r7vPXG2TpZZdnjU33ZIHb7+ZVdecCBQ7oRtu+3puu+KHbPq6kbQpaiSaP38ep3z+aHbafW+232m3F8b/9orLufn66zjxf07rmLNP1D+dcsOVDjWoTIUX5+qJV95jrrbJkssuz/iNt2DGP//K7Ecf4fIvHAHA/HnPcdkJR7DvCWfUXKHU3Pz58/nmF49hh1325NWv27XuctSiKjI1IqYCs4EFwPzM3CYixgEXAROBqcCBmTmr1zparqJnC4GeTuWcUE5Th1h7lcV3xt5po1W5//E5NVYjDd51VxiqdpIAACAASURBVF3BTrvZfcJw1dUVvQ6DsAGwHvCXMijXAv4cES+tsOShZq52mLmzn3zhhirzn3+OB+/4MyuPX4unZjwCFH3gTr3tBlZ+6dp1lin1KTP5v1NOZK1112PfAxff8f3PN/2BSy88l+O+9E2WWnqZJnNQJ6o4V0caM7UDPTv7KZ5vyNVpd93GuLU35O1fOZ/9Tjyb/U48m7FLLGXjrTpeZnL6N77ImutMZO+3H1x3OapAs0wdYK7ukplbZeY25fNjgasycyPgqvJ5r9p1Bu7HgKsi4m7gwXLcOsCGwIfbtEz14cS3vIyt11mJlZdZgss/uB2n/34qr91gHOuMW5bMZPrTz3HyFf+su0xpwJ6dO5e/3HIjH/jkZ+suRYNU5Yldmfk3YPXF846pwDaZ+Vh1Sxly5mqHmfPkE/z2rP9h4cIFZCYbvnon1t1iW35y8tE8/+wcMpPV1l6fnQ7x61Fnu/P227j6yp+z7vob8vEj3gnAIUd8mDP+9xTmzZvHCUd/AChuZPaBT5izw4UnTDdlpnaguU8/wfXf/zq5cCGZybpbv461XrFt3WVJA/bPv/+F31/1C9aeuCGf+eC7AHjHoR9i3rznOfc7X2P2U7P46uc/zrrrb8yxX/7fmqtVf7QxU/cFdi4fnwtcDRzTax2Z7bnyIyK6gG15ccfwf8rMBf15v10oaKQ4e9I2fb9IGiZeNmG5tsTXpsf+qtff/LtOemPTZUbEBRTBtxowAzg+M89smD6V4d+A23Ku2oWCRoo3bLB63y+ShoHN1mhPpkJruToatJqpYBcKGhn23tBM1cixzXorDvm+KsA/Tt7z/UDjfVqmlF3uvCAi7gNmAQl8NzOnRMSTmblyOT2AWYue96RdZ+CSmQuBG9o1f0nSyDFmzOCzNjMP6mP6xEHPvIOYq5Kk/molV0cDM1WS1F99ZWo/79nyusx8OCJWB66MiLu6zSMjomlDcdsacCVJ6i9vjiNJUnXMVUmSqlFFpmbmw+X/Z0bEpRRXgcyIiAmZOS0iJgAzm83D25NKkmrnzVYkSaqOuSpJUjVavYlZRCwXESssegy8AbgduByYVL5sEnBZs/l4Bq4kqXbuUEqSVB1zVZKkalSQqeOBS8szeccCP8jMKyLiT8DFEXE4cD9wYLOZ2IArSaqdO5qSJFXHXJUkqRqtZmpm3gts2cP4x4Hd+jsfG3AlSbWzrz5JkqpjrkqSVI1OyVQbcCVJtfNMIUmSqmOuSpJUjU7JVBtwJUm165RQlCRpJDBXJUmqRqdkqg24kqTadUooSpI0EpirkiRVo1My1QZcSVLtOqRbIUmSRgRzVZKkanRKptqAK0mqXacc1ZQkaSQwVyVJqkanZKoNuJKk2nV1ddVdgiRJI4a5KklSNTolU23AlSTVrlOOakqSNBKYq5IkVaNTMtUGXElS7TqlXyFJkkYCc1WSpGp0SqbagCtJql2nHNWUJGkkMFclSapGp2SqDbiSpNqN6ZBQlCRpJDBXJUmqRqdkqg24kqTadUooSpI0EpirkiRVo1MytTNupSZJGtUiotehH+89KyJmRsTtDeO+GhF3RcRfI+LSiFi5rSsgSVIHaSVXJUnSYs0ydShz1QZcSVLtuiJ6HfrhHGDPbuOuBDbPzC2AfwKfqbZiSZI6V4u5KkmSSs0ydShz1QZcSVLtxnRFr0NfMvNa4Ilu436dmfPLpzcAa1VftSRJnamVXAWIiDERcWtE/Kx8vl5E3BgR90TERRGxZFtXQJKkDtEsU4eyewUbcCVJtYtoNsTkiLi5YZg8wNkfBvyyHXVLktSJmuVqP30UuLPh+cnANzJzQ2AWcHi1FUuS1Jma76sOXR024EqSatfsiGZmTsnMbRqGKf2db0R8FpgPnN++6iVJ6iytnCkUEWsBbwLOKJ8HsCtwSfmSc4H92lS6JEkdpYozcKu4ssUGXElS7bq6otdhsCLiUGAf4ODMzKpqlSSp0zXL1X5c2fJN4NPAwvL5qsCTDV0TPQSsOUSrIklSrZpl6gD2V1u+ssUGXElS7cZE9DoMRkTsSbHz+ZbMnFNpsZIkdbhmudrsypaI2AeYmZm31Fi+JEkdo1mm9md/taorW8YOeg0kSapItNB5UERcAOwMrBYRDwHHA58BlgKuLOd9Q2Ye2XqlkiR1vhZydQfgLRGxN7A0sCJwKrByRIwtz8JdC3i4kkIlSepwfWVqeSVL49UsU7p1+7foypYVyueDurKlaQNuRPwv0Otlp5n5kb4WIElSX1q5e2dmHtTD6DMHX037mKuSpKEw2FzNzM9QHAQlInYGjs7MgyPih8D+wIXAJOCyaiptjbkqSWq3vjK1bKzt8T4tjVe2lLk6aH2dgXtzKzOXJKk/WunrdpgxVyVJbdeGXD0GuDAi/hu4lc45UGquSpLaqsVMrezKlqYNuJl5buPziFjWvgQlSVVr5Qzc4cRclSQNhSpyNTOvBq4uH98LbNvyTCtmrkqS2q3Fq0Uru7KlXzcxi4jtI+IO4K7y+ZYR8e3BlS9J0otFk2EkMlclSe1krpqrkqRqNMvUFnL1GOATEXEPRZ+4fV7Z0t+bmH0TeCNwOUBm/iUidhpslZIkNRotZ+A2MFclSW1jrpqrkqRqVJWprV7Z0t8GXDLzwW53XlswkAVJktSbUdQH7gvMVUlSu5irgLkqSapAp2RqfxtwH4yI1wIZEUsAHwXubF9ZkqTRZBSeKWSuSpLaxlw1VyVJ1eiUTO1vA+6RFHdJW5Pizmi/Bj7UrqIArj769e2cvTRkVnn1h+suQarM3Fu/1Zb5djtjZjQY8lw9cvv12jl7aciYqxop2pWpYK4yBLn66V02bOfspSFhpmokGen7qv1qwM3Mx4CD21yLJGmUGtMhoThUzFVJUjuZq5IkVaNTMrWrPy+KiI0j4qqIuL18vkVEfK69pUmSRouxXb0PI5G5KklqJ3PVXJUkVaNZpg5lrva6qIg4MiI2LZ+eDnwGmAeQmX8F3tn+8iRJo8GYruh1GCnMVUnSUDFXzVVJUjWaZepQ5mqztuLzgGPLx8tm5k3dps9vT0mSpNEmovdhBDFXJUlDwlwFzFVJUgWaZepQ5mqvfeBm5jMR8b7y6WMRsQGQABGxPzBtCOqTJI0CY0fYHmVPzFVJ0lAxV81VSVI1OiVTm97ELDPnlQ8/BEwBNo2Ih4H7sJN4SVJFRtIlnc2Yq5KkoWCumquSpGp0SqY2bcBdJDPvBXaPiOUoul2YQ9Gn0P1trE2SNEp0yEHNIWOuSpLayVw1VyVJ1eiUTG16v7SIWDEiPhMR34qIPSiCcBJwD3DgUBQoSRr5xnZFr8NIYq5KkoaCuWquSpKq0SxThzJX+zoD9/vALOB64H3AZ4EA3pqZt7W5NknSKDGm6eHE5iLiLGAfYGZmbl6OGwdcBEwEpgIHZuasVuusgLkqSWq7VnJ1mDFXJUlt1SmZ2lcD7vqZ+QqAiDiDoiP4dTLz2bZXJkkaNca0dl3KOcC3gO81jDsWuCozT4qIY8vnx7SykIqYq5KktmsxV4cTc1WS1Fadkql9tSMv6hSezFwAPGQYSpKq1hW9D33JzGuBJ7qN3hc4t3x8LrBfpQUPnrkqSWq7VnJ1mDFXJUlt1SxThzJX+zoDd8uIeLp8HMAy5fMAMjNXbGt1kqRRodmdPSNiMjC5YdSUzJzSxyzHZ+a08vF0YHxrFVbGXJUktV2n3DF7CJirkqS26pRMbdqAm5ljhqoQSdLo1SwUy8bavhpsm70/IyIH+/4qmauSpKHQKTub7WauSpLarVMyta8zcCVJars2dAw/IyImZOa0iJgAzKx8CZIkdahOueGKJEnDXadkaoeUIUkazbqIXodBuhyYVD6eBFxWSaGSJA0DbchVSZJGpWaZ2p9cjYilI+KmiPhLRPw9Ir5Qjl8vIm6MiHsi4qKIWLJ5HZIk1WxMV+9DXyLiAuB6YJOIeCgiDgdOAvaIiLuB3cvnkiSNCq3kqiRJWqxZpvYzV58Dds3MLYGtgD0jYjvgZOAbmbkhMAs4vNlM7EJBklS7VvoVysyDepm026BnKknSMNYp/fVJkjTctZqpmZnAM+XTJcohgV2Bd5XjzwVOAL7T23xswJUk1c4dTUmSqmOuSpJUjb4yNSImA5MbRk0pb8Td+JoxwC3AhsD/Af8CnszM+eVLHgLWbLYcG3AlSbXzik5JkqrTSq5GxNLAtcBSFPuLl2Tm8RGxHnAhsCrFTui7M/P5louVJKmD9ZWpZWPtlD5eswDYKiJWBi4FNq26DkmS2q4rotdBkiQNTIu5WklffZIkjQTNMnWg+6uZ+STwO2B7YOWIWHRi7VrAw03rGEzxkiRVaUxEr4MkSRqYVnI1C7311XdJOf5cYL921C5JUidplqn9ydWIeEl55i0RsQywB3AnRUPu/uXLJgGXNZuPXShIkmrXZV99kiRVptVcraKvPkmSRoIK9lUnAOeW2doFXJyZP4uIO4ALI+K/gVuBM5vNxAZcSVLtvBxEkqTqNMvV/txspYq++iRJGgla3VfNzL8Cr+xh/L3Atv2djw24kqTa2detJEnVaZar/bnZSsNrn4yIF/XVV56F22dffZIkjQSdsq/qSU+SpNrZB64kSdXphL76JEkaCVrtA7cqnoErSapd2FArSVJlWszVSvrqkyRpJOiUfVUbcCVJtfMeZpIkVaeVXK2qrz5JkkaCTtlXtQFXklQ7u0qQJKk65qokSdXolEy1AVeSVLtO6RhekqSRwFyVJKkanZKpNuBKkmrXRWeEoiRJI4G5KklSNTolU23AlSTVrqur7gokSRo5zFVJkqrRKZlqA64kqXad0q+QJEkjgbkqSVI1OiVTbcAdpfbaY1eWXW45xnR1MWbsGC64+Md1lyT122nHH8xeO23Oo0/MZpsDvgzA9096LxtNHA/Ayissw5Oz57LdO0+qs0wNQKf0KyT11+c/9xmuveZqxo1blR9f9rMXTTv3nLP4+ldP5urfX88qq4yrqUKp/1Zafhm+c/y72GyDCWTCkV84n39OncH3Tz6MddcYx/2PPMEhnz6TJ2fPrbtU9ZO5quHu++eew49/9EMigo022pgTv/QVllpqqbrLkvqlp1y98a/38YF3vp73H7gjCxYmV1x3O5899bK6S1U/dEqm2oA7ip1x9rnuWGpY+v5Pb+C0i67hjC++54Vx7z727Bcen/SJt/LUM+5kDifRYr9CEfFx4Agggb8B783MZysoTerRvvu9jYPedQif/cwxLxo/fdo0rv/DH5gwYY2aKpMG7muf3p9f//EO3vWpM1li7BiWXXpJPn34G7j6pn/wtbOv5Oj37sHR730Dn/t/7mgOF63mqlSnGTNm8IPzv8ell/+CpZdemk994qNc8Yufs+9b31Z3aVK/9JSrO22zEfvs/Aq2fcdJPD9vPi9ZZfm6y1Q/dUqmdkhPDpLUf3/487944qk5vU5/+x5bc/EVtwxhRWrVmIheh75ExJrAR4BtMnNzYAzwzjaXrFHuVdu8mhVXWuk/xn/15K/w8U9+iuiQI/VSX1Zcfmlet/UGnHPp9QDMm7+Ap56Zyz47b8F5P70RgPN+eiNv3mWLOsvUALWSq1InWLBgAc89+yzz589n7rPP8pLVV6+7JKlfesvVyQfsyNfOvpLn580H4NFZz9RZpgagWaYOZa56Bu5oFXDk+w4nItj/gHew/4HvqLsiqRI7bL0BM56Yzb8eeLTuUjQAXa3n3lhgmYiYBywLPNLyHKUB+t1vf8Pq41dnk003rbsUqd8mrrEqj816hilfOIRXbLwmt975IEefcgmrr7oC0x97GoDpjz3N6quuUHOlGogKclWqzfjx45l06GG8cfddWHrppdj+tTvw2h1eV3dZUr/0lqsbrrs6O7xyA77woTfz7PPz+MzXL+WWOx6ou1z1Q6dk6pCfgRsR720ybXJE3BwRN595+pShLGvUOef7F3DRJZfyf6edzkUXnM8tN/+p7pKkShy45zb88Iqb6y5DA9TsiGZjNpTD5Mb3ZubDwNeAB4BpwFOZ+es61qMO5mpnmDt3LmdM+S4f/PBH6y5FGpCxY8ew1aZrc/oPr2P7g05mztznOPqwPf7jdZk1FKdB64QzhYYrc7V+Tz/1FL/77VX84tdXceXvrmPu3Ln87Kd24aLhobdcHTumi3ErLcdO7/kax33jJ5x3ymF1l6p+6pQzcOvoQuELvU3IzCmZuU1mbnP4+yb39jJVYPz44mZPq666Krvuvge3/+2vNVcktW7MmC723XVLLvnVn+suRQMVvQ+N2VAOL9pjiohVgH2B9YA1gOUi4pChXYFamasd4KEHH+Dhhx/iwLfty1577MqMGdN55/5v47FHvRpAne3hGbN4eOaT/On2+wG49De3sdWmazPz8dm8dLUVAXjpaivy6BOz6yxTA9UkV9Unc7VmN9zwR9Zcay3GjRvHEksswW67v4G/3Hpr3WVJ/dJbrj4840l+ctVtANz89/tZuDBZzX5wh4dmmTqEudqWLhQiorfWwADGt2OZ6r85c+aQuZDlllueOXPmcP0f/8D7j/xg3WVJLdv1NZvwz6kzeHjmk3WXogFq8c6euwP3ZeajABHxY+C1wHkVlNYRzNXOt9HGm3D1dde/8HyvPXblBxdf4s1C1fFmPD6bh6bPYqN1V+fu+2ey87abcNe907nr3ukc8ubX8LWzr+SQN7+Gn13twf7hpFPumN2pzNXO9tIJa/DXv/yFuXPnsvTSS3PjDdez2eab112W1C+95eq9Dz3G61+9MdfefDcbrrM6Sy4xlsfsB3dY6JRMbVcfuOOBNwKzuo0P4I9tWqb66YnHH+fjH/kQAPMXLGDvN+3DDjvuVHNVUv+d+5VD2fFVG7HaystzzxVf5Iun/YJzf3I9B7zxVd68bJhqMRMfALaLiGWBucBuwEjrR8Nc7TDHHP0Jbv7TTTz55Cz22HUnPvCho3jb2w+ouyxpUD5x8g85+8uHsuTYMUx9+DEmH38eXV1dnHfyYUzab3semPYEh3z6rLrL1AB0yL5mJzNXO9gWW2zJHm94I+884K2MGTOWTV/2MvY/wHu2aPjoKVf/Pfd5vnvCwdz8w+N4ft4Cjvj89+suU/3UaqZGxNrA9yiyJ4EpmXlqRIwDLgImAlOBAzOzey4tnk+2oUOriDgTODszf9/DtB9k5rv6msez87GnLY0Iq7z6w3WXIFVm7q3fassu4S1Tn+71N/9VE1fsc5kR8QXgHcB84FbgiMx8rroK62WuSouZqxop2pWp0HqujnTmqlQwUzWS1LGvCn3nakRMACZk5p8jYgXgFmA/4FDgicw8KSKOBVbJzGN6m09bzsDNzMObTOszDCVJo0urSZuZxwPHV1FLJzJXJUkDMepbaPtgrkqS+quCfdVpFDfbJjNnR8SdwJoU93HZuXzZucDVwNA24EqSNBDhtZ6SJFXGXJUkqRp9ZWpETAYa72w5pfuNtxteOxF4JXAjML5s3AWYTh99sNuAK0mqXZf7mZIkVcZclSSpGn1latlY22ODbaOIWB74EfCxzHy6sWE4MzMimnbV0NWfYiVJaqtoMkiSpIExVyVJqkazTO1nrkbEEhSNt+dn5o/L0TPK/nEX9ZM7s9k8bMCVJNWuK6LXQZIkDYy5KklSNZplan9yNYpTbc8E7szMrzdMuhyYVD6eBFzWbD52oSBJqp37k5IkVcdclSSpGhVk6g7Au4G/RcRt5bjjgJOAiyPicOB+4MBmM7EBV5JUO88IkiSpOuaqJEnVaDVTM/P39N7Zwm79nY8NuJKk2rmbKUlSdcxVSZKq0SmZagOuJKl24ZlCkiRVxlyVJKkanZKp3sRMklS7ruh9kCRJA9NKrkbE2hHxu4i4IyL+HhEfLcePi4grI+Lu8v+rtHs9JEmqW7NMHcr9VRtwJUm1i4heB0mSNDAt5up84JOZuRmwHfChiNgMOBa4KjM3Aq4qn0uSNKI1y9Sh3F+1AVeSVLuI3gdJkjQwreRqZk7LzD+Xj2cDdwJrAvsC55YvOxfYrz3VS5LUOZpl6lDur9oHriSpdjbUSpJUnapyNSImAq8EbgTGZ+a0ctJ0YHw1S5EkqXN1yr6qDbiSpNp1dUoqSpI0AjTL1YiYDExuGDUlM6f08LrlgR8BH8vMpxsvE83MjIisrmJJkjpTp+yr2oArSapdh2SiJEkjQrNcLRtr/6PB9sXvjyUoGm/Pz8wfl6NnRMSEzJwWEROAmRWVK0lSx+qUfVX7wJUk1S6a/CdJkgamlVyN4lTbM4E7M/PrDZMuByaVjycBl1VeuCRJHaZZpg7l/qpn4EqSatfVYu5FxMrAGcDmQAKHZeb1rVcmSdLw02Ku7gC8G/hbRNxWjjsOOAm4OCIOB+4HDmxpKZIkDQOt7qtWxQZcSVLtovXrUk4FrsjM/SNiSWDZ1quSJGl4aiVXM/P30OspRbsNesaSJA1DFeyrVsIGXElS7Vo5qhkRKwE7AYcCZObzwPNV1CVJ0nDUKWcLSZI03HVKptoHriSpdhG9D/2wHvAocHZE3BoRZ0TEcm0tWJKkDtZirkqSpFKzTB3KXLUBV5JUu4hoNkyOiJsbhsnd3j4W2Br4Tma+Evg3cOyQr4QkSR2iWa5KkqT+62NfdcjqsAsFSVLtml2WkplTgClN3v4Q8FBm3lg+vwQbcCVJo1inXO4pSdJw1ymZ6hm4kqTaRZP/+pKZ04EHI2KTctRuwB3trFeSpE7WSq5KkqTFmmXqUOaqZ+BKkmpXwZUnRwHnR8SSwL3Ae1ueoyRJw5Q9JUiSVI1OyVQbcCVJtetqMRUz8zZgm2qqkSRpeGs1VyVJUqHVTI2Is4B9gJmZuXk5bhxwETARmAocmJmzmtbRUhWSJFWgE+7qKUnSSGGuSpJUjWaZ2s9cPQfYs9u4Y4GrMnMj4Cr6cQ8XG3AlSbVzR1OSpOqYq5IkVaPVBtzMvBZ4otvofYFzy8fnAvv1NR+7UJAk1c5LPSVJqo65KklSNfrK1IiYDExuGDUlM6f0MdvxmTmtfDwdGN9XHTbgSpJq536mJEnVMVclSapGX5laNtb21WDb7P0ZEdnX62zAlSTVzjOFJEmqjrkqSVI12pSpMyJiQmZOi4gJwMw+62hHFZIkDUQ0GSRJ0sCYq5IkVaNZpraQq5cDk8rHk4DL+nqDZ+BKkmoXnikkSVJlzFVJkqrRaqZGxAXAzsBqEfEQcDxwEnBxRBwO3A8c2Od8MvvsZkEjWERM7kfnylLHc1uW1An8LdJI4bYsqW7+DmmkcFtWFexCQZP7fok0LLgtS+oE/hZppHBbllQ3f4c0Urgtq2U24EqSJEmSJElSh7IBV5IkSZIkSZI6lA24sh8WjRRuy5I6gb9FGincliXVzd8hjRRuy2qZNzGTJEmSJEmSpA7lGbiSJEmSJEmS1KFswJUkSZIkSZKkDmUD7igVEXtGxD8i4p6IOLbueqTBioizImJmRNxedy2SRi9zVSOFuSqpE5irGgnMVFXJBtxRKCLGAP8H7AVsBhwUEZvVW5U0aOcAe9ZdhKTRy1zVCHMO5qqkGpmrGkHOwUxVRWzAHZ22Be7JzHsz83ngQmDfmmuSBiUzrwWeqLsOSaOauaoRw1yV1AHMVY0IZqqqZAPu6LQm8GDD84fKcZIkaeDMVUmSqmOuSlI3NuBKkiRJkiRJUoeyAXd0ehhYu+H5WuU4SZI0cOaqJEnVMVclqRsbcEenPwEbRcR6EbEk8E7g8pprkiRpuDJXJUmqjrkqSd3YgDsKZeZ84MPAr4A7gYsz8+/1ViUNTkRcAFwPbBIRD0XE4XXXJGl0MVc1kpirkupmrmqkMFNVpcjMumuQJEmSJEmSJPXAM3AlSZIkSZIkqUPZgCtJkiRJkiRJHcoGXEmSJEmSJEnqUDbgSpIkSZIkSVKHsgFXGqCIeFdErFN3HZIkjQTmqiRJ1TFXpZHJBlyNehGxICJui4jbI+KHEbFsk9ceDqyemQ/0Mv2ciNi/fHxGRGzWZF47R8RrG54fGRHvaWFVJEmqnbkqSVJ1zFVJAJGZddcg1SoinsnM5cvH5wO3ZObXG6aPzcz5/ZzXOcDPMvOSfrz2BOCZzPzaoAqXJKkDmauSJFXHXJUEnoErdXcdsGF5tPG6iLgcuCMixkTEVyPiTxHx14h4P0AUvhUR/4iI3wCrL5pRRFwdEduUj/eMiD9HxF8i4qqImAgcCXy8PJq6Y0ScEBFHl6/fKiJuKJd1aUSs0jDPkyPipoj4Z0TsOKSfjiRJA2OuSpJUHXNVGqXG1l2A1CkiYiywF3BFOWprYPPMvC8iJgNPZearI2Ip4A8R8WvglcAmwGbAeOAO4Kxu830JcDqwUzmvcZn5REScRsMRzYjYreFt3wOOysxrIuJE4HjgY+W0sZm5bUTsXY7fverPQpKkVpmrkiRVx1yVRjcbcCVYJiJuKx9fB5wJvBa4KTPvK8e/Adgiyv6CgJWAjYCdgAsycwHwSET8tof5bwdcu2hemflEs2IiYiVg5cy8phx1LvDDhpf8uPz/LcDE/q2iJElDxlyVJKk65qokG3AlYG5mbtU4IiIA/t04iuII46+6vW7v9pf3H54r/78A/w1LkjqPuSpJUnXMVUn2gSv106+AD0TEEgARsXFELAdcC7yj7HNoArBLD++9AdgpItYr3zuuHD8bWKH7izPzKWBWQ39B7wau6f46SZKGMXNVkqTqmKvSCOfREKl/zqC4/OPPURzufBTYD7gU2JWiL6EHgOu7vzEzHy37JPpxRHQBM4E9gJ8Cl0TEvsD/b+eOTQAEYjCM/mldUhzAfZzOVc5eLJUL8l5/kKsCX5H99mxNclTVkuRMsn3xKQCYxF4FgPfYq/BzNcaYPQMAAAAAAA+cUAAAAAAAaErABQAAAABoSsAFAAAAAGhKwAUAAAAAaErABQAAAABoSsAFAAAAvDlYIgAAABBJREFUAGhKwAUAAAAAaOoCnafbhYgJPSEAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "XOXibT_CN7a0"
      },
      "id": "XOXibT_CN7a0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "mhLCYlVhOBvB"
      },
      "id": "mhLCYlVhOBvB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test_2, y_predicted_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh4hui1aOCop",
        "outputId": "d1bcd3bd-dfd9-43dd-fb6a-4e8bff1d0a35"
      },
      "id": "Xh4hui1aOCop",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.65      0.68        20\n",
            "           1       0.71      0.77      0.74        22\n",
            "\n",
            "    accuracy                           0.71        42\n",
            "   macro avg       0.72      0.71      0.71        42\n",
            "weighted avg       0.71      0.71      0.71        42\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jWORxttXODzd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c16d84d-7138-4940-fe33-001270664347"
      },
      "id": "jWORxttXODzd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 74ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99622923]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Itpxrs4QOWop"
      },
      "id": "Itpxrs4QOWop",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}